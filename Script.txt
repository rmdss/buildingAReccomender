1. #Created the Cluster
2. wget http://files.grouplens.org/datasets/movielens/ml-1m.zip
unzip ml-1m.zip
3. cat ml-1m/ratings.dat | sed 's/::/,/g' | cut -f1-3 -d, > ratings.csv
4. hadoop fs -put ratings.csv /ratings.csv
5. mahout recommenditembased --input /ratings.csv --output recommendations --numRecommendations 10 --outputPathForSimilarityMatrix similarity-matrix --similarityClassname SIMILARITY_COSINE
6. hadoop fs -ls recommendations
   hadoop fs -cat recommendations/part-r-00000 | head
7. sudo pip3 install twisted
   sudo pip3 install klein
   sudo pip3 install redis
8. wget http://download.redis.io/releases/redis-2.8.7.tar.gz
   tar xzf redis-2.8.7.tar.gz
   cd redis-2.8.7
   make
   ./src/redis-server &
9. hello.py File
from klein import run, route
import redis
import os

# Start up a Redis instance
r = redis.StrictRedis(host='localhost', port=6379, db=0)

# Pull out all the recommendations from HDFS
p = os.popen("hadoop fs -cat recommendations/part*")

# Load the recommendations into Redis
for i in p:

  # Split recommendations into key of user id 
  # and value of recommendations
  # E.g., 35^I[2067:5.0,17:5.0,1041:5.0,2068:5.0,2087:5.0,
  #       1036:5.0,900:5.0,1:5.0,081:5.0,3135:5.0]$
  k,v = i.split('       ')
  #print(i)
  # Put key, value into Redis
  r.set(k,v)

# Establish an endpoint that takes in user id in the path
@route('/<string:id>')

def recs(request, id):
  # Get recommendations for this user
  v = r.get(id)
  return 'The recommendations are '+v.decode('utf-8')


# Make a default endpoint
@route('/')

def home(request):
  return 'Please add a user id to the URL, e.g. http://localhost:8090/1234n'

# Start up a listener on port 8090
run("localhost", 8090)

10. twistd -noy hello.py &
11. curl localhost:8090/37
12. Terminated the cluster